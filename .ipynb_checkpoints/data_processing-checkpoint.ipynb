{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise different fft size\n",
    "# Plot ema etc\n",
    "# create python file in github so Poalo can check!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from scipy import stats\n",
    "import numpy as np, pandas as pd\n",
    "import librosa, os\n",
    "import matplotlib.pyplot as plt\n",
    "from functions_processing import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%store -r ema_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=437, minmax=(5, 81), mean=31.05263157894737, variance=296.8481409946886, skewness=0.6788327610750112, kurtosis=-0.2882228123114503)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "longest_mel, shortest_mel, shapes_list = get_arr_length(df) # 28885 1102\n",
    "\n",
    "# Explore spread of dataset\n",
    "list_array = np.array(shapes_list)\n",
    "description = stats.describe(list_array)\n",
    "\n",
    "print(description)\n",
    "\n",
    "#create histogram with 4 bins\n",
    "plt.hist(shapes_list, bins=100, edgecolor='black'); # ';' removes array at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nchau\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Pass sr=22050, n_fft=1024, n_mels=128, fmin=0, fmax=11025.0 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n"
     ]
    }
   ],
   "source": [
    "df = prepare_dataframe(ema_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dataset(input_df):\n",
    "    data = np.asarray(input_df['Input'])\n",
    "    \n",
    "    container = []\n",
    "    len_X = len(input_df)\n",
    "\n",
    "    for i in range(len_X):\n",
    "        row_i = t[i].astype('float')\n",
    "        container.append(row_i)\n",
    "    \n",
    "    container = np.array(container).reshape(len_X, 128, 95, 1)   # batch size, height (features), width (duration), channel\n",
    "    \n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = input_dataset(train)\n",
    "X_test = input_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (349, 128, 95, 1)\n",
      "349 sample, 128 x 95 size mel spectogram.\n",
      "\n",
      "Test shape: (88, 128, 95, 1)\n",
      "88 sample, 128 x 95 size mel spectogram.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'sample,',X_train.shape[1] ,'x',X_train.shape[2] ,'size mel spectogram.\\n')\n",
    "print('Test shape:', X_test.shape)\n",
    "print(X_test.shape[0], 'sample,',X_test.shape[1] ,'x',X_test.shape[2] ,'size mel spectogram.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_dataset(input_df):\n",
    "    data = np.asarray(input_df['Label 1'])\n",
    "    \n",
    "    container = []\n",
    "    len_X = len(input_df)\n",
    "\n",
    "    for i in range(len_X):\n",
    "        row_i = t[i].astype('float')\n",
    "        container.append(row_i)\n",
    "    \n",
    "    container = np.array(container).reshape(len_X, 128, 95, 1)   # batch size, height, width, channel\n",
    "    \n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train['Label 1'])\n",
    "y_test = np.asarray(test ['Label 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuple with height and width of mel used to reshape arrays.\n",
    "mel_height = 128\n",
    "mel_width = 95\n",
    "\n",
    "mel_size_flat = mel_height * mel_width\n",
    "mel_shape = (mel_height, mel_width)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X_train\n",
    "train_Y = Y_train\n",
    "new_train_X = train_X.reshape(X_train.shape[0],mel_size_flat)\n",
    "new_test_X = X_test.reshape(X_test.shape[0],mel_size_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (349, 12160)\n",
      "Training set (labels) shape: (349,)\n",
      "Test set (images) shape: (88, 12160)\n",
      "Test set (labels) shape: (88,)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=new_train_X.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=y_train .shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=new_test_X.shape))\n",
    "print(\"Test set (labels) shape: {shape}\".format(shape=y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture hyper-parameter\n",
    "learning_rate = 0.001\n",
    "training_iters = 40000\n",
    "batch_size = 16\n",
    "display_step = 20\n",
    "\n",
    "n_input = mel_size_flat # 64x64 image\n",
    "dropout = 0.75 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paolo also used it from pytorch\n",
    "# normalise output, you can keep it between 0 and 1 so \n",
    "# it is easier for the model to be trained, MinMaxScaler for each label independently\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CNNDataSet(Dataset):\n",
    "    '''\n",
    "    Instance of class which iterates through this class when you need a new batch of a model.\n",
    "    ''' \n",
    "    def __init__(self, df):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        self.n_samples = df.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = torch.tensor(df['Inputs'].values) # size [n_samples, n_features]\n",
    "        self.y_data = torch.tensor(df['Label 1', 'Label 2', 'Label 3', 'Label 4', 'Label 5', 'Label 6',\n",
    "                  'Label 7', 'Label 8', 'Label 9', 'Label 10', 'Label 11', 'Label 12'].values) # size [n_samples, 1]\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "     \n",
    "# 12 x duration is the output\n",
    "# compute loss also on padding part so how do you train model not on padding\n",
    "# paolo split data into length of word batches where within batch difference was less than 5 ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\\\Users\\\\nchau\\\\Documents\\\\Work\\\\Nick Ramsey\\\\Code\\\\UMC\\\\data\\\\processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# convert raw audio to mel_spectogram\n",
    "def logmelfilterbank(audio,\n",
    "                     sampling_rate,\n",
    "                     fft_size=1024,\n",
    "                     hop_size=220,                                 # too match ema sampling rate\n",
    "                     win_length=None,\n",
    "                     window=\"hann\",\n",
    "                     num_mels=128,\n",
    "                     fmin=None,\n",
    "                     fmax=None,\n",
    "                     eps=1e-10,\n",
    "                     ):\n",
    "    ''' essentially the same as librosa.feature.melspectrogram + log10 '''\n",
    "\n",
    "    # get amplitude spectrogram\n",
    "    x_stft = librosa.stft(audio, n_fft=fft_size, hop_length=hop_size,\n",
    "                          win_length=win_length, window=window, pad_mode=\"reflect\")\n",
    "    spc = np.abs(x_stft).T  # (#frames, #bins)\n",
    "\n",
    "    # get mel basis\n",
    "    fmin = 0 if fmin is None else fmin\n",
    "    fmax = sampling_rate / 2 if fmax is None else fmax\n",
    "    mel_basis = librosa.filters.mel(sampling_rate, fft_size, num_mels, fmin, fmax)\n",
    "\n",
    "    return np.log10(np.maximum(eps, np.dot(spc, mel_basis.T)))\n",
    "\n",
    "# get longest and shortest mel spectogram array length >> 28885\n",
    "def get_arr_length(df):\n",
    "    \"\"\"Loads data and tracks longest mel spectogram array\n",
    "    :return counter: the longest length of array\n",
    "    \"\"\"\n",
    "    counter_longest = 0\n",
    "    counter_shortest = 3000 # arbritary number\n",
    "    shapes = []\n",
    "    shape_audio = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        mel_array = df.iloc[i, :]['Input']\n",
    "        shapes.append(mel_array.shape[0])\n",
    "        \n",
    "        if mel_array.shape[0] > counter_longest:\n",
    "            counter_longest = mel_array.shape[0]    \n",
    "            \n",
    "        elif mel_array.shape[0] < counter_shortest:\n",
    "            counter_shortest = mel_array.shape[0]\n",
    "            \n",
    "    return counter_longest, counter_shortest, shapes\n",
    " \n",
    "def prepare_dataframe(ema_list):\n",
    "    df = pd.DataFrame(columns=['Input', 'Label 1', 'Label 2', 'Label 3', 'Label 4', 'Label 5', 'Label 6',\n",
    "                              'Label 7', 'Label 8', 'Label 9', 'Label 10', 'Label 11', 'Label 12'])\n",
    "    \n",
    "    for i in range(len(ema_list)):\n",
    "        waveform = ema_list[i]['Audio'][0][0].values\n",
    "        mel_arr = logmelfilterbank(waveform, 22050)\n",
    "        mel_arr = librosa.util.fix_length(mel_arr.T, size=95)                             # add padding\n",
    "        \n",
    "        ema_columns = ['ul_0', 'ul_1', 'll_0', 'll_1', 'jw_0', 'jw_1', 'tt_0', 'tt_1', 'tb_0', 'tb_1', 'td_0', 'td_1']\n",
    "        ema_markers = ema_list[i]['Data'][0].loc[:, ema_columns]\n",
    "        ema_arr = (ema_markers.to_numpy()).T\n",
    "        \n",
    "        df = df.append({'Input': mel_arr, 'Label 1': ema_arr[0], 'Label 2': ema_arr[1], 'Label 3': ema_arr[2], \n",
    "                        'Label 4': ema_arr[3], 'Label 5': ema_arr[4], 'Label 6': ema_arr[5], 'Label 7': ema_arr[6], \n",
    "                        'Label 8': ema_arr[7], 'Label 9': ema_arr[8], 'Label 10': ema_arr[9], 'Label 11': ema_arr[10], \n",
    "                        'Label 12': ema_arr[11]}, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_pytorch)",
   "language": "python",
   "name": "env_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
